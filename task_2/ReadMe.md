# Задание 2 (комментарии)
Скажу честно, я скорее всего не до конца понял, что надо продемонстрировать, кроме достойного внимания кода, из уточнения понял, что вопреки моему предположению больший интерес представляет реализация контейнера, а не сетевого взаимодействия; также было предложено продемонстрировать умение пользоваться стандартной библиотекой. Исходил из этого.

## TCP V.S. UDP
Я выбрал, конечно же, TCP, потому что мало когда хочется иметь API по транспорту с негарантированной доставкой, но вообще выбор определяется многими факторами. Основной недостаток UPD оказывается при этот тот, что его надо сложно заставлять работать через NAT и маршрутизаторы с сетевыми фильтрами. Если же абстрагироваться от задачи, факторов много для выбора транспорта, например в беспроводных сетях проще добавить гарантированную доставку поверх UPD, чем наблюдать то, как джиттеринг гробит производительность TCP.

Можно заметить, что я читаю данные так, как будто они приходят за один раз. Что ж, это потому что скорее всего размер пакета с маааленьким JSON будет меньше, чем MSS. Для Ethernet (исходя из его MTU) это 1460 байт, так что код написан с таким вот допущением.

А ещё соединения в решении постоянные. Чаще всего все хотят сэкономить на тройных SYN-ACK рукопожатиях.

## ООП 

Ограничился PIMPL и чуть-чуть понаследовался. Считаю оправданным.

## Контейнер
Если честно, я не понял, как правильно выбрать контейнер в формулировке "писать и читать куда угодно, но не в массив", поэтому просто хотел найти компромисс между затраченными усилиями и интересностью решения. В итоге получился Striped Map (я не помню, где видел это название). Вообще, если бы я выбрал очередь и обращался бы к ней только в режиме FIFO, то мог бы где-то добыть lock-free её реализацию (множество их), т.к. моё текущее решение просто уменьшает гранулярность блокировок, не являясь lock-free (для словаря такое неоправданно сложно писать с нуля).  

Если свериться с *"Art of multiprocessor programming"*, то в зависимости от целей можно использовать skip-lists, refinable hasmap и много-много прочего.  Я же просто завёл rw-lock на каждый bucket хеш-словарика. Слышал на C++Russia 2019 доклад, где человек не стал заморачиваться и в реальном решении сделал такой хеш фиксированным, просто заранее очень большим. В принципе, в последней версии кода я выбрал такое число для изначального размера контейнера, чтобы можно было не думать о перехешировании, но сам механизм реализовал. Принцип у него несложный -- мьютексы начинают защищать более одного бакета, таких что между ними не может быть коллизий. Можно было бы реализовать ещё traits для такого контейнера, но это уж точно требует некоторого количества времени. 

До добавления в решение, шаблонный класс был протестирован, возможно не предельно тщательно, но был. Получение ключей нужно для демонстрации, вообще в такой задаче оно плохо вписывается, примерно как получение размера такого контейнера (смысл спорный в общем случае). Можно было бы дописать также и удаление, просто решение и так делалось довольно долго, поддержка удаления же не несла бы принципиально оригинальных решений.

Сложность доступа к элементам должна быть O(1) в среднем, то есть O(load_factor) == O( elem_count / size), затем перехеширование и нужно. 

Деревья (если писать std::map) делать конкуррентными очень сложно, очередь хороша когда не нужен произвольный доступ, в целом же данный текст не будет содержать ответа на вопрос "что лучше", потому что я не понял, для чего должно быть лучше =(

## Бенчмарк
На моих машинах получалось, что время на сетевое взаимодействие существенно превосходит время доступа к контейнеру. Ну, то есть постепенно контейнер наполняется записями, после нескольких повторных запусков 40-50 клиентов по 1000-3000 запросов, но не могу сказать, что где-то произошла огромная оптимизация. Возможно, надо было напихать миллион элементов. Возможно, надо было что-то ещё. Конкретики не было, потому я просто предоставил инструменты для логирования и бенчмаркинга. 

Помимо прочего были использованы *callgrind* & *LukeStackwalker*, увиденное не позволяло утверждать, что узким местом является именно контейнер. Повторюсь, возможно я недостаточно нагрузил импровизированный сервер.

## Что можно было бы улучшить
Если бы это было реальное решение рабочей задачи, то я бы взял RabbitMQ, а если нельзя было бы -- совместил бы ZeroMQ и libCDS (там превосходнейшие реализации многопоточных контейнеров). Транспорт мог бы быть организован примерно [так](https://bitbucket.org/MasterAler/zmq-qt-server-client-sample) , это самая ранняя версия решения, применённого в текущем рабочем проекте (до добавления критически необходимых вещей вроде версии протокола, авторизации, подписок и т.д.). 

---------------------
В общем, постарался, что-то сделал, остальное на суд читающего.